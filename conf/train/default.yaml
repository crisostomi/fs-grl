seed_index: 0
deterministic: False

trainer:
  fast_dev_run: False
  gpus: 1
  precision: 32
  max_epochs: 300  # 200 for everyone, 50 for reddit
  accumulate_grad_batches: 1
  num_sanity_val_steps: 2
  gradient_clip_val: 10.0
  val_check_interval: 1.0
  log_every_n_steps: 1
  deterministic: ${train.deterministic}

meta-testing-trainer:
  gpus: ${train.trainer.gpus}
  precision: ${train.trainer.precision}
  max_epochs: 1
  deterministic: ${train.deterministic}
  log_every_n_steps: 1


restore:
  ckpt_or_run_path: null
  mode: null # null, continue, hotstart

monitor:
  metric: 'loss/val/classification_loss_epoch'
  mode: 'min'

callbacks:
  - _target_: pytorch_lightning.callbacks.EarlyStopping
    patience: 50 # 50 for TL, 5 for DML
    verbose: False
    monitor: ${train.monitor.metric}
    mode: ${train.monitor.mode}

  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    save_top_k: 2
    verbose: False
    monitor: ${train.monitor.metric}
    mode: ${train.monitor.mode}

  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step"
    log_momentum: False

  - _target_: pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar
    refresh_rate: 20

distance-metric-learning-callbacks:
  - _target_: pytorch_lightning.callbacks.EarlyStopping
    patience: 40 # 3 only for reddit, 25 otherwise
    verbose: False
    monitor: ${train.monitor.metric}
    mode: ${train.monitor.mode}

  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step"
    log_momentum: False

  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    save_top_k: 2
    verbose: False
    monitor: ${train.monitor.metric}
    mode: ${train.monitor.mode}

  - _target_: pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar
    refresh_rate: 20

#  - _target_: fs_grl.callbacks.TSNEPlot
#    samples_per_class: 100
#    colors_path: ${oc.env:PROJECT_ROOT}/data/colors/${nn.data.dataset_name}.json
#    threedimensional: false

meta-testing-callbacks:

  - _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "step"
    log_momentum: False

  - _target_: pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar
    refresh_rate: 20

logging:
  upload:
    run_files: true
    source: true

  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    project: ${core.project_name}
    entity: gladia
    log_model: ${..upload.run_files}
    mode: 'online'
    tags: ${core.tags}

meta-testing-logging:
  upload:
    run_files: false
    source: false

  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    project: ${core.project_name}
    entity: gladia
    log_model: false
    mode: 'online'
